[{"id":0,"href":"/docs/work-experience/","title":"Work Experience","section":"Docs","content":" Work Experience # Staff Machine Learning Engineer # VerticalScope Inc. # Jan 2023 - Present - Toronto, CA # Working at Fora, a part of VerticalScope\u0026rsquo;s cloud-based digital platform that operates over 1,200 online communities connecting 110 million active users monthly, fostering their passions, and facilitating knowledge sharing. My role focuses on building healthier and better communities by empowering users with machine learning. Here are some of the tasks I have been responsible for: Empowering communities with machine learning to enhance user experience. Personalized Feed Recommendation\u0026rsquo;s, Newsletter growth, mobile notifications to all communities. Developing advanced search algorithms for accurate, tailored results. Optimizing product retrieval and facilitating new product discovery within communities. Answering user questions and providing technical support, using LLMs. Interviewing and mentoring junior engineers. Staff Machine Learning Engineer # Kalepa # Apr 2022 - Sep 2022 - Toronto, CA # Enhanced the in-house News Recommendation System using Sentence Embeddings. Identified and implemented Document Question Answering, as configurable classifiers to analysis various risks on businesses. Constructed and deployed an Entity Resolution System utilizing Unsupervised Contrastive Learning. improved top-20 search accuracy from 35% to 98% for 10^7+ entities. Cut down search latency from 1.5s to 0.3s. Crafted a scalable system employing Postgres, Onnx, Pinecone, fastAPI, with Dockerized deployment. Conducted 35+ candidate interviews and developed a system for pinpointing the most suitable candidates for respective roles. Principal Machine Learning Engineer # Airtel X-labs # Sep 2018 - Mar 2022 - Bangalore, IN # Led the product development of Voicebot engine which powers voice-based queries on the MyAirtel app with 10m MAU, in 7 indian languages, does 500k queries/day. (Speech to text, Text to speech, training and inference pipelines.) Voicebot integeration with PBX exchange like Asterix. Presented work at Nvidia GTC Winter 2020 Researched and deployed e2e OCR pipeline serving 1.6m docs/day at 96%+ accuracy, used by Airtel for its new customer acquisition journey ICDAR Rank 6 Building the workflow-orchestration engine which powers the customer support queries on mail / social media for Airtel, processes 50k emails/day, built on k8, temporal.io Supported 150 different workflows with ~50 activities running concurrently. Hired and led a team of 9 engineers. Co-founding Engineer # AuthME ID Solutions, Acquired by Airtel # Aug 2017 - Sep 2018 - Bangalore, IN # Built OCR pipeline for reading arbitrary documents, 5 step process with word localization, word recognition, clustering, parsing and serving. Built Voice based IVR bot for Indian business by building on top of DeepSpeech and Rasa NLU. Invited for YC 2018 Winter Interview Stage in San Francisco. Machine Learning Engineer # Krowd # June 2015 - Aug 2017 - Bangalore, IN # Recommendation \u0026amp; ranking for users by clustering restaurants into latent topics space and recommending fresh restaurants built on node.js. \u0026lt;200ms latency over a set of 1 million restaurants per user. Loyalty and rewards platform with second price ad bidding for banks (pilot run with Royal Bank of Scotland). Software Development Engineer # Amazon # Feb 2013 - Feb 2015 - Bangalore, IN # Built the auto correcting \u0026amp; predictive completion language keyboards for regions like germany, japan etc based on the hidden markov model. Worked on Developing \u0026amp; Deploying Amazon Instant Video on 13 different living room TV environments in 10 months to 1m+ customers. Scaling \u0026amp; building a/b testing framework to test the application across various regions. Associate Software Engineer # Kony Labs # July 2011 - Nov 2012 - Hyderabad, IN # Developed a JavaScript single templating based backend/frontend framework. Integrated native platform level code with existing Lua code using Foreign Function Interface. "},{"id":1,"href":"/docs/open-source/","title":"Open Source Contributions","section":"Docs","content":" Open Source Contributions # SymSpellCppPy # Python library for Spelling correction based on SymSpell written in C++ and exposed to python via pybind11.\nComparing Contrastive losses on Vision \u0026amp; NLP # Comparing performance of different InfoNCE type losses used in contrastive learning.\nWindy Lunar Lander Env # Exploring Reinforcement Learning algorithms on customized Lunar Lander environment with dynamic realistic wind vectors by extending the gym environment.\nBlaze # ML inference framework for pytorch models in Asynchronous C++ which supports dynamic batching, Arrayfire, quantized model, and various optimizations written using Drogon\nSABER # Easily reproducible machine learning baseline for automatic speech recognition using semi-supervised contrastive learning.\nEpoch-Synchronous Overlap-Add (ESOLA) # Fast C++ implementation of ESOLA using KFRLib, can be used for online time-stretch augmentation during SpeechToText training.\nNewman # Initial Contributor to Newman which is a command-line collection runner for Postman.\nPostman Interceptor # Initial Contributor to Postman Interceptor a helper extension for the Postman packaged app.\n"},{"id":2,"href":"/docs/machine-learning/","title":"Machine Learning Toolkit","section":"Docs","content":" Machine Learning Toolkit: Skills and Expertise # Data Engineering # Expertise in building unbiased datasets via feature-based sampling. Proficient in generating synthetic data matching real data distribution. Skilled in augmentation techniques for vision, speech, NLP. Modelling and Feature Engineering # Comprehensive knowledge of Convolutional, Recurrent, and Transformer-based models. Experience with feature importance techniques. Proficient with Contrastive Learning methods like SimCLR, BYOL, SimSiam. Well-versed in model debugging and profiling. Experienced with topic models using Probabilistic Graphic Models and embedding-based clustering. Training # Proficient in distributed training using OpenMPI + RoCE, Torch RPC. Skilled in Pytorch Lightning optimizations. Calibration # Expertise in implicit calibration techniques like Focal Loss, Maximum Entropy Regularization, Label Smoothing, Random Dropout. Experience with explicit calibration techniques like Isotonic Regression, Platt\u0026rsquo;s scaling. Optimizations # Skilled in model optimizations such as Quantization, Pruning, Distillation. Proficient in ML Ops Fusing techniques like ONNX, TorchDynamo, TVM. Inference # Expertise in C++ inference using ONNX \u0026amp; Drogon. Experience with frameworks like Triton, Mosec. Skilled in scaling on k8 using OKD. Proficient in monitoring and alerting using Vector.io, Prometheus, Grafana. Online Monitoring # Expertise in hard negative mining around calibrated threshold region. Experience with sampling and saving hard negatives. Skilled in detecting and alerting on Model and Data Drifts. "},{"id":3,"href":"/docs/posts/ml_engineer_guidelines/","title":"Machine Learning Engineer Roadmap","section":"Posts","content":" Mastering the Art of AI Development: A Detailed Roadmap from Data to Deployment # Introduction # Developing an effective artificial intelligence (AI) model is akin to embarking on a long, complex journey. It demands expertise in areas ranging from dataset creation and feature engineering to model tuning, evaluation, and deployment. This blog post will walk you through the key stages involved in AI development, explain the importance of each, and provide a clear understanding of the skills required at different levels of expertise, namely Junior, Senior, and Staff Engineer.\n1. Dataset Creation: Building a Solid Foundation # A robust AI model requires a strong foundation, and this begins with creating an appropriate dataset. The cornerstone of a good dataset is relevant data. How do you identify what\u0026rsquo;s relevant? It\u0026rsquo;s about understanding the signal-to-noise ratio, where the \u0026lsquo;signal\u0026rsquo; is the useful information that can answer your research questions, and \u0026rsquo;noise\u0026rsquo; is the irrelevant data that may skew your results.\nA robust dataset is characterized by comprehensive and diverse features. It should also encompass labeled and unlabeled data. While labeled data serves as the ground truth for training the model, unlabeled data, despite being more challenging to work with, can unearth hidden patterns or associations.\nWe must also address potential implicit bias in our dataset. Bias can skew the model\u0026rsquo;s performance and harm its ability to make fair decisions. Careful data collection, rigorous analysis, and bias-correction techniques can help account for it.\n2. Feature Engineering: Turning Raw Data into Meaningful Information # Once we have a dataset, it\u0026rsquo;s time for feature engineering. This process involves selecting the most relevant features and transforming raw data into formats that the model can understand better.\nFeaturization techniques like one-hot encoding, binning, or polynomial features can be employed depending on the nature of your data. The distribution of the dataset also plays a key role in deciding which features to include.\nNormalization is another crucial step to ensure that extreme values or outliers don\u0026rsquo;t distort the model\u0026rsquo;s performance. This depends on the specific distribution of your data and the problem you\u0026rsquo;re trying to solve.\n3. Modeling: Choosing and Improving Your Tool # The modeling stage is where the magic happens. This is where we choose the algorithm that will learn from our data. We begin with a baseline modelâ€”a simple technique that sets the minimum performance expectation.\nBaseline models come with their own pros and cons. For example, a linear regression model may be easy to implement and interpret but may not handle complex relationships between features and outcomes well. We need to contextualize these models with our problem at hand.\nNext, we move on to more advanced models. We might opt for neural networks or ensemble methods, depending on the problem. These models need to be fine-tuned to handle bias and adapt to the specific context of the problem. This involves choosing appropriate optimization and loss functions.\n4. Evaluation Measure: Assessing Your Model # Now, we need to assess how our model performs. Depending on the problem, we could use measures like accuracy, precision, recall, or the F1 score for classification problems, or mean squared error, mean absolute error, or R-squared for regression problems.\nThese evaluation measures each have their strengths and limitations, and they assess both extrinsic and intrinsic properties of the model. For instance, accuracy might be a good measure when the classes are balanced, but it would be misleading for imbalanced datasets.\n5. Confidence Scoring and Tuning: Trusting Your Model # Confidence scoring helps us understand how certain our model is about its predictions. A well-calibrated model\u0026rsquo;s confidence aligns well with its accuracy. Both pre-training (like regularization techniques) and post-training methods (like Platt scaling) can help us calibrate our models.\nWhile it\u0026rsquo;s useful in identifying model issues, it\u0026rsquo;s important to remember that a high confidence score doesn\u0026rsquo;t always mean a correct prediction and vice versa.\n6. Inference: Deploying Your Model # Once we\u0026rsquo;re satisfied with the model\u0026rsquo;s performance, we\u0026rsquo;re ready to deploy it. This requires careful planning, from selecting the appropriate hardware to efficiently using the cores and instructions. The choice between different precision formats like int8, fp16, bf16, etc., depends on the trade-off we want to make between speed and accuracy.\nMoreover, understanding concepts like queuing theory, throughput, and latency relationships can help scale models effectively.\n7. Optimizations/Improvements Cycle: Enhancing Your Model # After deployment, our job isn\u0026rsquo;t over. We need to continuously monitor our model\u0026rsquo;s performance and make necessary improvements. This might involve tweaking features, changing the model architecture, or even collecting more data.\n8. Monitoring and Metrics: Keeping an Eye on Your Model # An effective monitoring system is crucial in maintaining the performance of our models. We need to set up alerts for key performance metrics and keep a close eye on these online metrics. Following a systematic MLOps architecture helps manage models better.\n9. User Feedback Pipeline: Learning from Your Users # Incorporating user feedback into our model improvements is vital. We need to be alert to concept drifts, where the relationships between variables change over time, and hard negatives that are consistently misclassified. Understanding the impact of both implicit and explicit feedback can help fine-tune our model further.\nThe Path to AI Mastery: Skills at Different Levels # While a Junior AI engineer should be aware of the entire development pipeline, they are expected to show proficiency (scoring 3) in dataset creation, feature engineering, modeling, evaluation, and inference, with a basic understanding (scoring 2) in other areas.\nA Senior AI engineer should exhibit minimum proficiency in all stages and demonstrate advanced knowledge (scoring 4) in key areas.\nA Staff engineer, the highest level, should have expert-level knowledge and skills (scoring 5) in multiple key areas and be able to demonstrate substantial outcomes.\nBuilding an AI model is a complex task that requires a wide array of skills. But with the right understanding, continuous learning, and constant practice, you can embark on this exciting journey with confidence. Happy modeling!\n"},{"id":4,"href":"/docs/posts/supervised_finetuning/","title":"Supervised Fine-Tuning in Large Language Models","section":"Posts","content":" The Power of Supervised Fine-Tuning in Large Language Models: An In-depth Analysis # Introduction # In recent years, the development of machine learning, particularly large language models (LLMs), has revolutionized the way we approach a multitude of challenges, from query-based tasks to content generation. In this post, we will dive deep into a technique gaining traction within the AI community - supervised fine-tuning using domain-specific instruction datasets - and contrast it with the more conventional prompt tuning approach, with a focus on techniques such as retrieval augmentation.\nWhat is Supervised Fine-Tuning? # Supervised fine-tuning involves adjusting a pre-trained LLM to improve its performance using a specific dataset that contains examples from a targeted domain. For instance, to train an LLM for medical consultation, one might use a dataset comprising medical textbooks, research papers, and patient-doctor interactions. Using instruction-answer-context pairs from social media conversations to build better contextual assistants.\nForming the Dataset # Creating an effective dataset for supervised fine-tuning is a nuanced process. The dataset must be a balanced representation of the domain you\u0026rsquo;re aiming to specialize in, so it\u0026rsquo;s vital to include diverse and contextually rich information sources. Privacy and data ethics are of paramount concern during the data collection process.\nAdvantages of Supervised Fine-Tuning # Domain Specificity: Supervised fine-tuning allows the model to be customized to a particular domain, resulting in more accurate and contextually relevant outputs. Better Generalization: A fine-tuned model can generalize better to new data within the same domain, as it has learned the specific patterns and nuances of the field. Efficient Usage of Parameters: Fine-tuning allows the vast parameter space of LLMs to be effectively utilized for domain-specific tasks, leading to parameter-efficient fine-tuning. Limitations of Supervised Fine-Tuning # Dataset Quality: The success of supervised fine-tuning largely hinges on the quality of the dataset. Poorly curated or biased datasets can lead to subpar or skewed results. Overfitting: The model can overfit to the training data, leading to less than optimal performance on unseen data. Resource-Intensive: Fine-tuning requires significant computational resources, making it more expensive than some other methods. Comparison with Prompt Tuning # Prompt tuning, by contrast, employs a more straightforward approach, guiding the LLM to generate desired responses using specifically crafted prompts. While this method is simpler and less resource-intensive, it lacks the domain specificity and generalization capabilities offered by supervised fine-tuning.\nRetrieval Augmentation # One method commonly used in prompt tuning is retrieval augmentation, where the model is trained to pull in relevant external information to enhance its responses. While this can lead to more informative replies, the quality of the output still largely depends on the relevancy and accuracy of the external data sourced, which can be a hit-or-miss.\nParameter-Efficient Fine-Tuning # Parameter-efficient fine-tuning refers to the idea of making the best use of the available parameters in a model during the fine-tuning process. With supervised fine-tuning, this can be achieved by selectively updating parameters that contribute most to the target domain, thereby improving the model\u0026rsquo;s performance while keeping computational costs in check.\nConclusion # Both supervised fine-tuning and prompt tuning have their place in the world of large language models. The choice between the two often depends on the specific requirements of the task at hand, the resources available, and the complexity of the domain. In tasks where domain-specific accuracy and robust generalization are of paramount importance, supervised fine-tuning with a well-curated instruction dataset appears to hold the edge. The resource-intensiveness and potential overfitting risks associated with it, however, call for careful implementation and ongoing evaluation. As the field evolves, the development of even more efficient and effective tuning techniques will undoubtedly continue.\n"},{"id":5,"href":"/docs/posts/hard_negatives/","title":"The Role of Negative Mining in Machine Learning: Bridging the Gap in Model Performance","section":"Posts","content":" Introduction # Machine learning models are excellent tools for making predictions or classifications. However, they\u0026rsquo;re not infallible; occasionally, they may make mistakes. Some of the most enlightening mistakes are the so-called \u0026ldquo;hard negatives\u0026rdquo; â€” instances where the model confidently produces the incorrect output. Understanding and learning from these instances through hard negative mining can significantly improve the model\u0026rsquo;s performance.\nUnderstanding Hard Negative Mining # In machine learning, \u0026ldquo;hard negatives\u0026rdquo; refer to examples that are challenging for the model to classify correctly. They are the negatives that the model most often misclassifies. Hard negative mining is a strategy for improving the performance of a model by focusing on these difficult-to-classify instances.\nWhy is it Important to Measure Performance in the Threshold Region? # The threshold region is where the model makes its most decisive judgments. It is in this region that we identify the hard negatives. By focusing on the threshold region, we can specifically diagnose where the model struggles and concentrate our efforts to improve those areas.\nHow to Identify Hard Negatives # Typically, hard negatives are identified by observing the model\u0026rsquo;s performance in real-world scenarios. Debugging these cases can often lead to revealing insights about the model\u0026rsquo;s shortcomings. During this process, it\u0026rsquo;s crucial to analyze the model outputs concerning the features, thereby identifying potential missing properties in the feature set that lead to incorrect predictions.\nTraining Strategies to Address Hard Negatives # Once the hard negatives have been identified and analyzed, the next step is to use this information to improve the model. This might involve:\nExpanding the training set: Incorporating more examples of hard negatives into the training set can improve the model\u0026rsquo;s ability to correctly classify these cases in the future. Fine-tuning the model: Sometimes, it may not be necessary to retrain the entire model. Instead, you could fine-tune the model on the hard negatives, enabling it to learn from its mistakes without needing to revisit all the previous training data. Revising the features: If the hard negatives are a result of inadequate or poor features, consider revising the feature set. This could involve engineering new features or improving the quality of existing ones. Conclusion # Hard negative mining is a powerful technique for improving the performance of machine learning models. By focusing on the hardest examples, we can refine our models to become more robust and accurate. The insights gained from studying these difficult cases can also help us improve our features and make our models even more effective.\n"},{"id":6,"href":"/docs/posts/entity_resolution/","title":"Entity Resolution using Contrastive Learning","section":"Posts","content":" Introduction to Entity Resolution # Entity resolution (also known as entity matching, record linkage, or duplicate detection) is the task of finding records that refer to the same real-world entity across different data sources (e.g., data files, books, websites, and databases).\nThis can be a challenging task, especially when the dataset is large and the queries mention the attributes of the entities in various ways, such as with partial information, typing errors, abbreviations, or extra information. In this blog post, we\u0026rsquo;ll be discussing how to approach the Entity Resolution Problem and the solution that was implemented to solve it.\nProblem Definition # Imagine you have a dataset of approximately 50 million entities, and your task is to find the right entity for a given query. The query could be a few of the entity\u0026rsquo;s attributes, and these queries could mention the attributes in various ways. This is the Entity Resolution Problem.\nThe Existing Solution # One solution to this problem is an Elastic search-based match, which uses complicated heuristics that are overfitted on a small training set. However, this solution is not scalable and the accuracy of the top-20 search retrieval decreases exponentially as the number of entities increases.\nAt the time this problem was being addressed, the top-20 search retrieval accuracy was around 40% for the current number of entities.\nThe Implemented Solution # To solve the Entity Resolution Problem, an embedding search was implemented using a Sentence embedding model. The Deberta model was pretrained and fine-tuned for the current problem using contrastive learning. In contrastive learning, positive pairs are generated using augmentations for each attribute that best mock the queries, based on the many user queries received.\nCustom augmentations which syntheically generate query like variations were used during training time to help the model learn generate positive similarity score for entity, query pair.\nResults # With this solution, the top-20 accuracy was around 98%. Heuristics and other business logic, along with a properly calculated confidence measure (which was hyperparameter-tuned on the validation set), were used to filter out the right entity. After the final pipeline was implemented, a top-1 accuracy of around 99.995% (precision) and 86% (recall) was achieved for high confidence matches.\nIn the end, pinecone was chosen for the embedding search and the search latency was around 100ms for the top 50 among the 50 million embeddings.\nConclusion # To conclude, the Entity Resolution Problem was successfully solved by implementing an embedding search using a Sentence embedding model and fine-tuning it with contrastive learning. This solution had a significantly higher accuracy compared to the existing Elastic search-based solution and was able to scale well as the number of entities increased.\n"}]