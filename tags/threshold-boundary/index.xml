<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Threshold Boundary on /home/vigi99</title><link>https://viig99.github.io/tags/threshold-boundary/</link><description>Recent content in Threshold Boundary on /home/vigi99</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 22 May 2023 22:03:59 -0400</lastBuildDate><atom:link href="https://viig99.github.io/tags/threshold-boundary/index.xml" rel="self" type="application/rss+xml"/><item><title>The Role of Negative Mining in Machine Learning: Bridging the Gap in Model Performance</title><link>https://viig99.github.io/docs/posts/hard_negatives/</link><pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate><guid>https://viig99.github.io/docs/posts/hard_negatives/</guid><description>Introduction # Machine learning models are excellent tools for making predictions or classifications. However, they&amp;rsquo;re not infallible; occasionally, they may make mistakes. Some of the most enlightening mistakes are the so-called &amp;ldquo;hard negatives&amp;rdquo; â€” instances where the model confidently produces the incorrect output. Understanding and learning from these instances through hard negative mining can significantly improve the model&amp;rsquo;s performance.
Understanding Hard Negative Mining # In machine learning, &amp;ldquo;hard negatives&amp;rdquo; refer to examples that are challenging for the model to classify correctly.</description></item></channel></rss>